{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9d9737616514b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Az eredményeket mentsd a src/weekly modul-ba weekly_test_6.py néven"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9789db8f0fbd7ec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Használható modulok: pathlib, pandas, typing, str, statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea6e648868022e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3799142958.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[2], line 2\u001B[0;36m\u001B[0m\n\u001B[0;31m    pip install fastparquet\u001B[0m\n\u001B[0m        ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "datalib = Path.cwd().parent.joinpath('data')\n",
    "pip install fastparquet\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:53:48.971483Z",
     "start_time": "2023-10-30T09:53:48.960111Z"
    }
   },
   "id": "b0b5dd4685315eda"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26aec7b4e97407",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1., Olvasd be a data mappa sp500.parquet nevű fájlját egy DataFrame-be. A betöltéshez használt engine paramétere legyen fastparquet\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.11 from \"/Users/molnartamas07/Documents/ECOPY_23241/venv/bin/python\"\n  * The NumPy version is: \"1.25.2\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Fájl beolvasása a fastparquet motort használva\u001B[39;00m\n\u001B[1;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_parquet(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msp500.parquet\u001B[39m\u001B[38;5;124m'\u001B[39m, engine\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfastparquet\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/ECOPY_23241/venv/lib/python3.11/site-packages/pandas/__init__.py:16\u001B[0m\n\u001B[1;32m     13\u001B[0m         _missing_dependencies\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_dependency\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_e\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _missing_dependencies:  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m     17\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to import required dependencies:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(_missing_dependencies)\n\u001B[1;32m     18\u001B[0m     )\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;66;03m# numpy compat\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.11 from \"/Users/molnartamas07/Documents/ECOPY_23241/venv/bin/python\"\n  * The NumPy version is: \"1.25.2\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('sp500.parquet', engine='fastparquet')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:36:59.601507Z",
     "start_time": "2023-10-30T09:36:59.244037Z"
    }
   },
   "id": "43f685fc4780d23a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2., Olvasd be az ff_factors.parquet fájlt egy DataFrame-be. A betöltéshez használt engine paramétere legyen fastparquet\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d42ee754b557dcef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('ff_factors.parquet', engine='fastparquet')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c757103536fa82f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c977da040d844",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3., Kapcsold össze a két DataFrame-t egy új DataFrame-be. Az összekapcsolás módja, hogy a hozam adatokra balról kapcsoljuk rá a factor adatokat a 'Date' elsődleges kulcs alapján.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Joined data](../resources/weekly6/joined_data.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf54c6765186a23e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Első DataFrame beolvasása\n",
    "sp500_df = pd.read_parquet('sp500.parquet', engine='fastparquet')\n",
    "\n",
    "# Második DataFrame beolvasása\n",
    "ff_factors_df = pd.read_parquet('ff_factors.parquet', engine='fastparquet')\n",
    "\n",
    "# Összekapcsolás a 'Date' oszlop alapján\n",
    "merged_df = sp500_df.merge(ff_factors_df, on='Date', how='left')\n",
    "\n",
    "# Eredmény DataFrame ellenőrzése\n",
    "print(merged_df)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34bc40351687c32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10fafbf699543d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4., Készíts egy új 'Excess Return' nevű oszlopot, ami a havi hozamok és a kockázat mentes hozam (RF) különbsége\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Kockázatmentes hozam oszlopból és havi hozamokból számított 'Excess Return' oszlop hozzáadása\n",
    "merged_df['Excess Return'] = merged_df['Monthly Return'] - merged_df['RF']\n",
    "\n",
    "# Eredmény DataFrame ellenőrzése\n",
    "print(merged_df)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdc8822a72cb19f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5., Rendezd sorba dátum szerint az adatokat, majd generálj egy új oszlopot ('ex_ret_1'), amely minden ticker ('Symbol') esetén 1-el eltolja az Excess Return értékeit olyan módon, hogy minden sorban szerepeljen a következő időszaki Excess Return érték. \n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6af93a4a3c53398"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![new column](../resources/weekly6/ex_ret_1.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6be746933376572"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Első DataFrame beolvasása\n",
    "sp500_df = pd.read_parquet('sp500.parquet', engine='fastparquet')\n",
    "\n",
    "# Második DataFrame beolvasása\n",
    "ff_factors_df = pd.read_parquet('ff_factors.parquet', engine='fastparquet')\n",
    "\n",
    "# Összekapcsolás a 'Date' oszlop alapján\n",
    "merged_df = sp500_df.merge(ff_factors_df, on='Date', how='left')\n",
    "\n",
    "# Dátum szerinti rendezés\n",
    "merged_df = merged_df.sort_values(by='Date')\n",
    "\n",
    "# Excess Return oszlop eltolása minden ticker esetén\n",
    "merged_df['ex_ret_1'] = merged_df.groupby('Symbol')['Excess Return'].shift(-1)\n",
    "\n",
    "# Eredmény DataFrame ellenőrzése\n",
    "print(merged_df)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2285003630c207d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd1aa0c59afb47",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6., A meglévő adathalmazt írd felül olyan módon, hogy egyszer törlöd az össze olyan sort, amely az 'ex_ret_1' oszlopban hiányos, majd ezt követően, törlöd az összes olyan sort, ami a 'HML' oszlopban hiányos\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Töröld az olyan sorokat, amelyekben az 'ex_ret_1' oszlop hiányos\n",
    "merged_df = merged_df.dropna(subset=['ex_ret_1'])\n",
    "\n",
    "# Töröld az olyan sorokat, amelyekben a 'HML' oszlop hiányos\n",
    "merged_df = merged_df.dropna(subset=['HML'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f333cdfad16d315f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637c401e0e6352c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A meglévő adatokból válaszd ki a Amazon részvényhez tartozó sorokat (AMZN) és töröld a tickereket tartalmazó oszlopot\n",
    "\n",
    "7., Készíts egy új LinearRegressionSM elnevezésű osztályt. Definiáld benne a __init__ nevű függvényt, amely bemenetként 2 DataDrame-t kap amelyeket ments le a left_hand_side és right_hand_side elnevezésű változókba. Az egyik DataFrame fogja tartalmazni a következő hónap többlet hozamait (left_hand_side), a másik a piaci hozamokat (Mkt-RF), az SMB és a HML értékeket (right_hand_side).\n",
    "\n",
    "8., Egésztsd ki az osztályt egy fit metódussal, ami meghívja a statsmodels segítségével OLS alapon becsült modellt illeszt az osztály adattagjaira. A becslésből visszakapott modellt mentse le az osztály _model adattagjába. Figyelj oda, hogy a regresszió futtatása során konstans (alfa / béta_0) is szerepeljen a predictor változók között.\n",
    "\n",
    "9., Egészítsd ki az osztályt egy get_params metódussal, ami visszaadja a becsült modellt béta paramétereinek értékeit. A visszakapott pandas Series típusú adatban az oszlop neve legyen 'Beta coefficients'\n",
    "\n",
    "10., Egészítsd ki az osztályt egy get_pvalues metódussal, ami visszaadja a becsült modell paraméterekhez tartozó p értékeket. A visszakapott pandas Series típusú adatban az oszlop neve legyen: P-values for the corresponding coefficients\n",
    "\n",
    "11., Egészítsd ki az osztályt egy get_wald_test_result metódussal, ami visszaadja a bemeneti restrikciós mátrix alapján számolt F és p értékeket. A visszatérési típus string legyen, a visszaadandó szöveg: F-value: fvalue, p-value: pvalue, ahol az fvalue és pvalue helyére 3 tizedesjegyre kerekítve adja meg a hozzájuk tartozó értékeket.\n",
    "\n",
    "12., Egészítse ki az osztályt egy get_model_goodness_values metódussal, ami visszadja a módosított R-négyzet, az Akaike és a Bayes információs kritériumok értékét. A visszatérési típus string legyen, a visszaadandó szöveg: Adjusted R-squared: ars, Akaike IC: ak, Bayes IC: by, ahol ars, ak és by helyére 3 tizedesjegyre kerekítve adja meg a hozzájuk tartozó értékeket.\n",
    "\n",
    "A létrehozott osztályt és a hozzátartozó metódusokat mentsd le a src.linear_regression mappába, a LinearRegressions.py fájlba.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "632e9b84be1a75ef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
